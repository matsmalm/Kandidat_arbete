\section{The greedy algorithm approach}
\subsection{Description of greedy algorithms}

Greedy algorithms can be either itterative or recursive. In most cases a itterative algorithm can be reformulated as a recursive one and vice versa. For simplicity we will consider the greedy algorithms itterative unless stated otherwice. In each itteration the algorithm has a set of possible alternatives on how to to push the algorithm towards a solution. A so called "cost function" designates a cost to each alternative. At the end of the itteration the alternative with the best cost, be it maximum or minimun, is choosen as a part of the solution. \\
\\It is not guaranteed in general that greedy algorithms provide optimal solutions. Also there is no general way of determining wether an greedy algorithm provides an optimal solution or not, but there are two very important properties that usually helps to determine if an optimal solution can be provided. These are the greedy-choice property and the optimal substructure property (referens [10] kap 16.2). The greedy choice property states that an global optimal solution can be arrived at by making locally optimal choices. In other words, at each itteration a choice can be made without reconsidering previous itterations. The optimal substructure property states that an optimal solution can be expressed as a sum of solutions to subproblems. If these two properties are fullfilled, then a solution can be constructed by summing optimal subsolutions. Hopefully this is an optimal solution, but if one want's to be shure more rigorous proofs are needed. 

%By formulationg algorithm recursion one it is easier to apply induction for a formal proof of a solution to be optimal. 
%If the greedy algorithm is recursively formulated we can describe the two properties as follows: Suppose that we have a optimization problem P, and that there exists an optimal solution S. Also, suppose that P has optimal substructure and greedy choice properties. Then a solution S* is given by the optimal subsolution $p_0$ plus the solution to the remainding problem P'. Following this line of thought again for P' one gets that $S*=p_0 +p_1 + solution (P'') =>S*=sum(p_i)$ 

%the problematics, as always with recursion, is to find a proper generic question. so that it is solvable, and so that it actually returns the answer we excpect to find.
  
%when constructing the algorithm for a problem P one starts out by finding some part of the solution. formulate this as a generic step and loop. This is exactly how the algorithm for the multi pursuer problem has been constructed.

\subsection{Development process for the greedy algorithm}
When constructing a greedy algorithm one often starts by finding some part of the final solution and then extend this to find a correct generic question for recursion. As in the examples given in the online lectures \cite{online lecture} the question and answer yielding a correct algorithm may not be intuitive. In the approach of creating the greedy algorithm for our problem we assume that it is possible to find the best movement strategy by locally finding the best next step until we arrive at a totally secured state of the enviroment. So the generic question would informally be "what is the best next step for the pursuer team?". In the development process for the greedy algorithm there has been a couple of candidates to answer this question. At last only one seemed like a good choice, presented in section 3.
\\
\\The first candidate "alorithm 1" was to make the secured area our objective function. In each itteration we consider the next move for each hunter in the team, and try to move the whole group so that we maximize the secured area (the objective function). We would then have a objective function and constraints due to the enviroment and pursuer positions. This ought to be possible to solve as some sort of linear programming problem. After consideration this approach presented several drawbacks. First off, for many enviroments it is sometimes nessecary to let go of secured areas. This could not be alowed by algorithm 1 with a greedy approach. Also there are a lot of cases where the best move is not an increase in secured area, but rather guarding or transportation to strategic positions. This was allowed, but not very likely to be chosen by the algorithm due to the greedy approach. It was thus realized that the algorithm somehow must look further than just the head on approach of targeting the secured area.
\\
\\The next candidate was an attempt to extend the formulation of algorithm 1 to have dynamic constraints, hereon called algorithm 2. The idea was to introduce some sort of tactics to the pursuer team, and thus make the group cooperate in a favorable manor. For each pursuer a certain tactic would be given, corresponding to constraints to the objective function. In order to formulate these constraints, we needed more information. Here the idea of introducing different areas was first met. The common vision of the pursuer team divides the enviroment into several subareas, not visible by the team. Depending on the state and geometry of these subareas each hunter was supposed to either guard, secure or divide a given subarea. This is dynamic information about the current enviroment, thus giving dynamic constraints for each pursuer. In this case it was problematic to find a general formulation of how to choose a tactic, and how to formulate these tactics as constraints for the objective function. Also there were to many special cases and intuition involved for a possible implementation.
\\%fram hit har jag kollat....
\\For the third candidate the idea was to use the extra enviromental information about the non visible areas and somehow apply this to a simple greedy cost function. By designating costs to each tile it would be easy to make a greedy choice. By construction each hunter can in general move to at most four tiles or stand still. Thus by giving each of these five alternatives a value that quantifies how good the move is we'll find the best over all strategy of the team. With this setup the objective function for each itteration is to maximize the sum of the tile-values that each pursuer moves into. So, how does one quantify what  a good tile is? The obvious answers such as field of vision and state are, by them self, insufficent information for a good algorithm. But by using the dynamic information of the areas resulting from the pursuers vision, we can find more parameters to quantify the best move. In order for the pursuer team to spread out and cooperate we designate a unique area for each pursuer to approach. This is done by adding a value to the tiles that give the shortest path for a specific pursuer to approach its designated boundry. Furthermore we add a value to all moveable tiles depending on their unique guarding properties of priorized areas. The algorithm will now make good tactical descisions, given that the added values are correctly adjusted. 
\\
\\This last candidate is was used as a basis for the final algorithm.To arrive at the algorithm presented in section 3 several examples has been tested manualy on random enviroments. In the manual execution the aim was to delete all human intuition from the algorithm and strictly quantify the valuation of the tiles with simple numbers or questions, suitable for a computer. A more in depth explanation of the algorithm is given in the next section.
 \pagebreak
\subsection{The greedy algorithm for our problem}
In this section the final greedy algorithm will be explained in detail, step by step. We see in Figure 4.1 a flow chart of the algorithm. Before the algorithm is started a prefunction is executed to find all static information on the enviroment. since these static conditions only need to be evaluated once, and can be evaluated at any time they are not an interesting part of the algorithm.
\begin{wrapfigure}{L}{0.6\textwidth}
  \centering
  \includegraphics[width=0.6\textwidth]{chapter_4_methods/greedy_uml2.jpg}
  \caption[Flow chart of greedy algorithm]
  {Flow chart of greedy algorithm}
\end{wrapfigure}
-punkta upp pseudokod fšr en itteration

1- find the total vision of the pursuers.
2- identify all elements of the set  A, where each element is an unseen area of the map.
3 - for each component in A identify its boundrys, and its priority
	a- only one bound, visible, contamined
	b- only one bound, not visible, contamined
	c- several bounds, visible, contamined
	d-several bounds, not visible, contamined
	e- secured area.
4- extend the boundrys of areas with priority a,c,e so that every tile where you can see the whole interior is part of the boundry.
(5- check if any hunter can make a move without changing the current conditions. if so, create  a fictional hunter int this position. (this is really the same thing as mergeing tiles)
6- create a table. each row is a contamined area , each column is a hunter. each element $c_ij$i n the table is the shortes distance for hunter j to the boundry of area i.
7- if the number of hunters is equal to or less than the number of columns. choose exactly one element from each row and column so that the sum is minimized. also areas of priority a,c must be choosen before areas of priorit d and b. this will assign a hunter to each area. add a value alpha in the first tile part of the shortest path to that area boundry for each hunter.
8- for each hunter add a value beta to the tile closest to a boundry of contamined area.
9- for each hunter add a value gamma to the tiles where the hunter still can see boundrys that are uniquley seen by this hunter.
10- for each hunter add a value delta to the tiles with largest vision.
11- if one or more tiles have the exact same value at this point, add a small value epsilon to the tile that is furthest away from the other hunters.
12 - move each hunter to the tile with the highest value, (this could also mean to stand still)



\subsection{Our implementation of the greedy algorithm.}
A description of how the algorithm is implemented.

before starting the algorithm all static conditions are evaluated and stored. this is done in a so called pre-function. the pre-function for the greedy algorithm runs the A-star algorithm to find the shortest path and distance between any two tiles in the map and stores this information in a hash table. also all the information from the graph network presented in chapter three is given. The pre prefunction also puts the hunters in their starting positions and evaluates the starting states of all tiles.

due to a combination of time pressure and shortcommings in programming with the C language, the implementation of the greedy algorithm was not finnished. but the outline is as follows:

given the data from the prefunction:
test if the enviroment is cleared. if not
test if the given break condition is reached. if not
run the function oneitteration().
 
the function oneitteration is in turn divided into three smaller functions preparations, valuation, execute.
int the preparation function. the algorithm  completes step one to five, given in the previous subsection.
in the valuation function it completes step six to eleven in the previous subsection.
at last in the execute function it moves each pursuer to the most valuated tile and uppdates the states of the enviroment.


